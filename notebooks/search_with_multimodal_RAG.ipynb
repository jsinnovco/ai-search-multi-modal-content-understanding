{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Retrieval Augmented Generation with Content Understanding\n",
    "\n",
    "# Overview\n",
    "\n",
    "Azure AI Content Understanding provides a powerful solution for extracting data from diverse content types, while preserving semantic integrity and contextual relationships ensuring optimal performance in Retrieval Augmented Generation (RAG) applications.\n",
    "\n",
    "This sample demonstrates how to leverage Azure AI's Content Understanding capabilities to extract:\n",
    "\n",
    "- OCR and layout information from documents\n",
    "- Image description, summarization and classification\n",
    "- Audio transcription with speaker diarization from audio files\n",
    "- Shot detection, keyframe extraction, and audio transcription from videos\n",
    "\n",
    "This notebook illustrates how to extract content from unstructured multimodal data and apply it to Retrieval Augmented Generation (RAG). The resulting output can be converted to vector embeddings and indexed in Azure AI Search. When a user submits a query, Azure AI Search retrieves relevant chunks to generate a context-aware response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "1. Follow [README](../README.md#configure-azure-ai-service-resource) to create essential resource that will be used in this sample\n",
    "2. Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyMuPDF in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (1.26.5)\n",
      "Requirement already satisfied: azure-ai-documentintelligence in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: azure-core in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (1.36.0)\n",
      "Requirement already satisfied: azure-identity in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (1.25.1)\n",
      "Requirement already satisfied: azure-search-documents in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 5)) (11.6.0b3)\n",
      "Requirement already satisfied: cffi in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: langchain in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: tiktoken in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 8)) (0.12.0)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 9)) (1.1.1)\n",
      "Requirement already satisfied: pillow in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 10)) (12.0.0)\n",
      "Requirement already satisfied: requests in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 11)) (2.32.5)\n",
      "Requirement already satisfied: langchain-openai in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: langchain-community in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 13)) (0.4)\n",
      "Requirement already satisfied: langchain-core in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 14)) (1.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 15)) (1.0.0)\n",
      "Requirement already satisfied: langchainhub in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 16)) (0.1.21)\n",
      "Requirement already satisfied: openai in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 17)) (2.5.0)\n",
      "Requirement already satisfied: Flask==2.2.5 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 18)) (2.2.5)\n",
      "Requirement already satisfied: flask-cors==5.0.1 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 19)) (5.0.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.18.0 in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 20)) (12.27.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /home/vscode/.local/lib/python3.11/site-packages (from Flask==2.2.5->-r ../requirements.txt (line 18)) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/vscode/.local/lib/python3.11/site-packages (from Flask==2.2.5->-r ../requirements.txt (line 18)) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from Flask==2.2.5->-r ../requirements.txt (line 18)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.0 in /home/vscode/.local/lib/python3.11/site-packages (from Flask==2.2.5->-r ../requirements.txt (line 18)) (8.3.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-documentintelligence->-r ../requirements.txt (line 2)) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-documentintelligence->-r ../requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 4)) (46.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 4)) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: azure-common>=1.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-search-documents->-r ../requirements.txt (line 5)) (1.1.28)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi->-r ../requirements.txt (line 6)) (2.23)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain->-r ../requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/vscode/.local/lib/python3.11/site-packages (from langchain->-r ../requirements.txt (line 7)) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core->-r ../requirements.txt (line 14)) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core->-r ../requirements.txt (line 14)) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core->-r ../requirements.txt (line 14)) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core->-r ../requirements.txt (line 14)) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-core->-r ../requirements.txt (line 14)) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/vscode/.local/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r ../requirements.txt (line 14)) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/vscode/.local/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r ../requirements.txt (line 14)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/vscode/.local/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r ../requirements.txt (line 14)) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vscode/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->-r ../requirements.txt (line 7)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r ../requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r ../requirements.txt (line 7)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r ../requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/vscode/.local/lib/python3.11/site-packages (from tiktoken->-r ../requirements.txt (line 8)) (2025.9.18)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 11)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 11)) (2.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai->-r ../requirements.txt (line 17)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai->-r ../requirements.txt (line 17)) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /home/vscode/.local/lib/python3.11/site-packages (from openai->-r ../requirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/vscode/.local/lib/python3.11/site-packages (from openai->-r ../requirements.txt (line 17)) (4.67.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-community->-r ../requirements.txt (line 13)) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-community->-r ../requirements.txt (line 13)) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-community->-r ../requirements.txt (line 13)) (3.13.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-community->-r ../requirements.txt (line 13)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-community->-r ../requirements.txt (line 13)) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-community->-r ../requirements.txt (line 13)) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/vscode/.local/lib/python3.11/site-packages (from langchain-community->-r ../requirements.txt (line 13)) (2.3.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 13)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 13)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 13)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 13)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 13)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 13)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r ../requirements.txt (line 13)) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/vscode/.local/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r ../requirements.txt (line 13)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r ../requirements.txt (line 13)) (0.9.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->-r ../requirements.txt (line 13)) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r ../requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /home/vscode/.local/lib/python3.11/site-packages (from langchainhub->-r ../requirements.txt (line 16)) (2.32.4.20250913)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from Jinja2>=3.0->Flask==2.2.5->-r ../requirements.txt (line 18)) (3.0.3)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r ../requirements.txt (line 4)) (2.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load and validate Azure AI Services configs\n",
    "AZURE_AI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\")\n",
    "AZURE_AI_SERVICE_API_VERSION = os.getenv(\"AZURE_AI_SERVICE_API_VERSION\") or \"2024-12-01-preview\"\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\") or \"2024-11-30\"\n",
    "\n",
    "# Load and validate Azure OpenAI configs\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_CHAT_API_VERSION = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\") or \"2024-08-01-preview\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\") or \"2023-05-15\"\n",
    "\n",
    "# Load and validate Azure Search Services configs\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") or \"sample-doc-index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create custom analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.passthrough import RunnablePassthrough\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents.base import Document\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create analyzers with pre-defined schemas.\n",
    "Feel free to start with the provided sample data as a reference and experiment with your own data to explore its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created analyzer: doc-analyzere235f26b-a945-47fe-9609-e2ba0cc7b483\n",
      "Successfully created analyzer: image-analyzer5a137efd-df2d-40a8-af7a-91a2d5f5ebe4\n",
      "Successfully created analyzer: audio-analyzera6e3a249-5a9c-4233-8700-3ed740d421e6\n",
      "Successfully created analyzer: video-analyzer6c99d63a-c371-48b3-add8-f45b5478339e\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "#set analyzer configs\n",
    "analyzer_configs = [\n",
    "    {\n",
    "        \"id\": \"doc-analyzer\" + str(uuid.uuid4()),\n",
    "        \"template_path\": \"../analyzer_templates/content_document.json\",\n",
    "        \"location\": Path(\"../data/credit_card_application_JessicaSmith.pdf\"),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"image-analyzer\" + str(uuid.uuid4()),\n",
    "        \"template_path\": \"../analyzer_templates/image_chart_diagram_understanding.json\",\n",
    "        \"location\": Path(\"../data/SSN_JessicaSmith.png\"),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"audio-analyzer\" + str(uuid.uuid4()),\n",
    "        \"template_path\": \"../analyzer_templates/call_recording_analytics.json\",\n",
    "        \"location\": Path(\"../data/callCenterRecording.mp3\"),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"video-analyzer\" + str(uuid.uuid4()),\n",
    "        \"template_path\": \"../analyzer_templates/video_content_understanding.json\",\n",
    "        \"location\": Path(\"../data/FlightSimulator.mp4\"),\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create Content Understanding client\n",
    "content_understanding_client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "    api_version=AZURE_AI_SERVICE_API_VERSION,\n",
    "    token_provider=token_provider,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/content_extraction\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    ")\n",
    "\n",
    "# Iterate through each config and create an analyzer\n",
    "for analyzer in analyzer_configs:\n",
    "    analyzer_id = analyzer[\"id\"]\n",
    "    template_path = analyzer[\"template_path\"]\n",
    "\n",
    "    try:\n",
    "        \n",
    "        # Create the analyzer using the content understanding client\n",
    "        response = content_understanding_client.begin_create_analyzer(\n",
    "            analyzer_id=analyzer_id,\n",
    "            analyzer_template_path=template_path\n",
    "        )\n",
    "        result = content_understanding_client.poll_result(response)\n",
    "        print(f\"Successfully created analyzer: {analyzer_id}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create analyzer: {analyzer_id}\")\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use created analyzers to extract multimodal content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer Results:\n",
      "Analyzer ID: doc-analyzere235f26b-a945-47fe-9609-e2ba0cc7b483\n",
      "{\n",
      "  \"analyzerId\": \"doc-analyzere235f26b-a945-47fe-9609-e2ba0cc7b483\",\n",
      "  \"apiVersion\": \"2024-12-01-preview\",\n",
      "  \"createdAt\": \"2026-01-16T19:12:31Z\",\n",
      "  \"warnings\": [],\n",
      "  \"contents\": [\n",
      "    {\n",
      "      \"markdown\": \"# Credit Card Application For Woodgrove Bank\\n\\n\\n## Personal Identification Details\\n\\nFirst Name: Jessica\\n\\nLast Name: Smith\\n\\nDate of Birth: 1990-05-15\\n\\nGender: Female\\n\\n\\n## Contact & Address Information\\n\\nEmail: jessica.smith@example.com\\n\\nPhone: (555) 123-4567\\n\\nAddress: 123 Main Street\\n\\nCity: Cityville\\n\\nState: CA\\n\\nZip Code: 90210\\n\\nYears Stayed at Current Address: 5\\n\\n\\n## Employment & Income Information\\n\\nEmployment Status: Full-Time\\n\\nYears in Job: 7\\n\\nEducation: Bachelor's Degree\\n\\nSource of Income: Salary\\n\\nMonthly Income: $6,500\\n\\nMonthly Expenses: $3,000\\n\\nMonthly Mortgage: $1,200\\n\\n\\n## Financial & Banking Information\\n\\nBank Name: Woodgrove Bank\\n\\nType of Account: Checking\\n\\nCredit Score: 750\\n\\nCard Preferences\\n\\nPreferred Card: Woodgrove Platinum Credit Card\\n\\nConsent & Agreements\\n\\n\\u2612\\nI agree to terms and conditions\\n\",\n",
      "      \"kind\": \"document\",\n",
      "      \"startPageNumber\": 1,\n",
      "      \"endPageNumber\": 1,\n",
      "      \"unit\": \"inch\",\n",
      "      \"pages\": [\n",
      "        {\n",
      "          \"pageNumber\": 1,\n",
      "          \"angle\": 0.02742189,\n",
      "          \"width\": 8.5,\n",
      "          \"height\": 11\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Analyzer ID: image-analyzer5a137efd-df2d-40a8-af7a-91a2d5f5ebe4\n",
      "{\n",
      "  \"analyzerId\": \"image-analyzer5a137efd-df2d-40a8-af7a-91a2d5f5ebe4\",\n",
      "  \"apiVersion\": \"2024-12-01-preview\",\n",
      "  \"createdAt\": \"2026-01-16T19:12:39Z\",\n",
      "  \"warnings\": [],\n",
      "  \"contents\": [\n",
      "    {\n",
      "      \"markdown\": \"![image](image)\\n\",\n",
      "      \"fields\": {\n",
      "        \"Title\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"Social Security Card\"\n",
      "        },\n",
      "        \"ChartType\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"box\"\n",
      "        },\n",
      "        \"TopicKeywords\": {\n",
      "          \"type\": \"array\",\n",
      "          \"valueArray\": [\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Identification\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Personal Information\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Social Security\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"DetailedDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"The image is a representation of a Social Security card. It features the text 'SOCIAL SECURITY' at the top. Below that, there is a placeholder for a Social Security Number (SSN) formatted as '123-45-6789'. The text 'is valid for SOCIAL SECURITY ADMINISTRATION' is printed in red below the SSN. The name 'JESSICA SMITH' is prominently displayed in the center. At the bottom, there is a line labeled 'SIGNATUAURE' for a signature.\"\n",
      "        },\n",
      "        \"Summary\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"This is a mock-up of a Social Security card, showing a sample SSN and the name 'Jessica Smith'. It includes standard elements like the SSN, name, and a signature line.\"\n",
      "        },\n",
      "        \"MarkdownDataTable\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"\"\n",
      "        },\n",
      "        \"AxisTitles\": {\n",
      "          \"type\": \"object\",\n",
      "          \"valueObject\": {\n",
      "            \"xAxisTitle\": {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"\"\n",
      "            },\n",
      "            \"yAxisTitle\": {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"FootnotesAndAnnotations\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"document\",\n",
      "      \"startPageNumber\": 1,\n",
      "      \"endPageNumber\": 1,\n",
      "      \"unit\": \"pixel\",\n",
      "      \"pages\": [\n",
      "        {\n",
      "          \"pageNumber\": 1\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Analyzer ID: audio-analyzera6e3a249-5a9c-4233-8700-3ed740d421e6\n",
      "{\n",
      "  \"analyzerId\": \"audio-analyzera6e3a249-5a9c-4233-8700-3ed740d421e6\",\n",
      "  \"apiVersion\": \"2024-12-01-preview\",\n",
      "  \"createdAt\": \"2026-01-16T19:12:51Z\",\n",
      "  \"warnings\": [],\n",
      "  \"contents\": [\n",
      "    {\n",
      "      \"markdown\": \"```WEBVTT\\n\\n00:00.080 --> 00:00.640\\n<v Agent>Good day.\\n\\n00:00.880 --> 00:02.240\\n<v Agent>Welcome to Contoso.\\n\\n00:02.560 --> 00:03.760\\n<v Agent>My name is John Doe.\\n\\n00:03.920 --> 00:05.120\\n<v Agent>How can I help you today?\\n\\n00:05.440 --> 00:06.320\\n<v Customer>Yes, good day.\\n\\n00:06.640 --> 00:08.160\\n<v Customer>My name is Maria Smith.\\n\\n00:08.560 --> 00:11.360\\n<v Customer>I would like to inquire about my current point balance.\\n\\n00:11.680 --> 00:12.560\\n<v Agent>No problem.\\n\\n00:12.880 --> 00:13.920\\n<v Agent>I am happy to help.\\n\\n00:14.240 --> 00:16.720\\n<v Agent>I need your date of birth to confirm your identity.\\n\\n00:17.120 --> 00:19.600\\n<v Customer>It is April 19th, 1988.\\n\\n00:20.000 --> 00:20.480\\n<v Agent>Great.\\n\\n00:20.800 --> 00:24.160\\n<v Agent>Your current point balance is 599 points.\\n\\n00:24.560 --> 00:26.160\\n<v Agent>Do you need any more information?\\n\\n00:26.480 --> 00:27.200\\n<v Customer>No, thank you.\\n\\n00:27.600 --> 00:28.320\\n<v Customer>That was all.\\n\\n00:28.720 --> 00:29.360\\n<v Customer>Goodbye.\\n\\n00:29.680 --> 00:31.920\\n<v Agent>You're welcome, goodbye a Cantoso.```\",\n",
      "      \"fields\": {\n",
      "        \"Sentiment\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"Neutral\"\n",
      "        },\n",
      "        \"Summary\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"Maria Smith contacted Contoso to inquire about her current point balance. Agent John Doe assisted her by confirming her identity and informing her that she has 599 points. Maria thanked the agent and ended the call.\"\n",
      "        },\n",
      "        \"Categories\": {\n",
      "          \"type\": \"array\",\n",
      "          \"valueArray\": [\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Retail\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"Companies\": {\n",
      "          \"type\": \"array\",\n",
      "          \"valueArray\": [\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Contoso\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"People\": {\n",
      "          \"type\": \"array\",\n",
      "          \"valueArray\": [\n",
      "            {\n",
      "              \"type\": \"object\",\n",
      "              \"valueObject\": {\n",
      "                \"Name\": {\n",
      "                  \"type\": \"string\",\n",
      "                  \"valueString\": \"John Doe\"\n",
      "                },\n",
      "                \"Role\": {\n",
      "                  \"type\": \"string\",\n",
      "                  \"valueString\": \"Agent\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"object\",\n",
      "              \"valueObject\": {\n",
      "                \"Name\": {\n",
      "                  \"type\": \"string\",\n",
      "                  \"valueString\": \"Maria Smith\"\n",
      "                },\n",
      "                \"Role\": {\n",
      "                  \"type\": \"string\",\n",
      "                  \"valueString\": \"Customer\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"Topics\": {\n",
      "          \"type\": \"array\",\n",
      "          \"valueArray\": [\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Point balance inquiry\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Customer service\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Identity confirmation\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Contoso services\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"string\",\n",
      "              \"valueString\": \"Account information\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 0,\n",
      "      \"endTimeMs\": 32182,\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 80,\n",
      "          \"endTimeMs\": 640,\n",
      "          \"text\": \"Good day.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 80,\n",
      "              \"endTimeMs\": 280,\n",
      "              \"text\": \"Good\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 280,\n",
      "              \"endTimeMs\": 640,\n",
      "              \"text\": \"day.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 880,\n",
      "          \"endTimeMs\": 2240,\n",
      "          \"text\": \"Welcome to Contoso.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 880,\n",
      "              \"endTimeMs\": 1360,\n",
      "              \"text\": \"Welcome\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 1360,\n",
      "              \"endTimeMs\": 1480,\n",
      "              \"text\": \"to\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 1480,\n",
      "              \"endTimeMs\": 2240,\n",
      "              \"text\": \"Contoso.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 2560,\n",
      "          \"endTimeMs\": 3760,\n",
      "          \"text\": \"My name is John Doe.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 2560,\n",
      "              \"endTimeMs\": 2720,\n",
      "              \"text\": \"My\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 2720,\n",
      "              \"endTimeMs\": 2960,\n",
      "              \"text\": \"name\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 2960,\n",
      "              \"endTimeMs\": 3120,\n",
      "              \"text\": \"is\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 3120,\n",
      "              \"endTimeMs\": 3440,\n",
      "              \"text\": \"John\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 3440,\n",
      "              \"endTimeMs\": 3760,\n",
      "              \"text\": \"Doe.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 3920,\n",
      "          \"endTimeMs\": 5120,\n",
      "          \"text\": \"How can I help you today?\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 3920,\n",
      "              \"endTimeMs\": 4120,\n",
      "              \"text\": \"How\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 4120,\n",
      "              \"endTimeMs\": 4240,\n",
      "              \"text\": \"can\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 4240,\n",
      "              \"endTimeMs\": 4320,\n",
      "              \"text\": \"I\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 4320,\n",
      "              \"endTimeMs\": 4640,\n",
      "              \"text\": \"help\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 4640,\n",
      "              \"endTimeMs\": 4720,\n",
      "              \"text\": \"you\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 4720,\n",
      "              \"endTimeMs\": 5120,\n",
      "              \"text\": \"today?\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Customer\",\n",
      "          \"startTimeMs\": 5440,\n",
      "          \"endTimeMs\": 6320,\n",
      "          \"text\": \"Yes, good day.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 5440,\n",
      "              \"endTimeMs\": 5760,\n",
      "              \"text\": \"Yes,\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 5760,\n",
      "              \"endTimeMs\": 5960,\n",
      "              \"text\": \"good\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 5960,\n",
      "              \"endTimeMs\": 6320,\n",
      "              \"text\": \"day.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Customer\",\n",
      "          \"startTimeMs\": 6640,\n",
      "          \"endTimeMs\": 8160,\n",
      "          \"text\": \"My name is Maria Smith.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 6640,\n",
      "              \"endTimeMs\": 6880,\n",
      "              \"text\": \"My\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 6880,\n",
      "              \"endTimeMs\": 7120,\n",
      "              \"text\": \"name\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 7120,\n",
      "              \"endTimeMs\": 7280,\n",
      "              \"text\": \"is\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 7280,\n",
      "              \"endTimeMs\": 7680,\n",
      "              \"text\": \"Maria\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 7680,\n",
      "              \"endTimeMs\": 8160,\n",
      "              \"text\": \"Smith.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Customer\",\n",
      "          \"startTimeMs\": 8560,\n",
      "          \"endTimeMs\": 11360,\n",
      "          \"text\": \"I would like to inquire about my current point balance.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 8560,\n",
      "              \"endTimeMs\": 8640,\n",
      "              \"text\": \"I\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 8640,\n",
      "              \"endTimeMs\": 8800,\n",
      "              \"text\": \"would\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 8800,\n",
      "              \"endTimeMs\": 9040,\n",
      "              \"text\": \"like\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 9040,\n",
      "              \"endTimeMs\": 9200,\n",
      "              \"text\": \"to\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 9200,\n",
      "              \"endTimeMs\": 9720,\n",
      "              \"text\": \"inquire\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 9720,\n",
      "              \"endTimeMs\": 9920,\n",
      "              \"text\": \"about\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 9920,\n",
      "              \"endTimeMs\": 10080,\n",
      "              \"text\": \"my\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 10080,\n",
      "              \"endTimeMs\": 10440,\n",
      "              \"text\": \"current\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 10440,\n",
      "              \"endTimeMs\": 10720,\n",
      "              \"text\": \"point\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 10720,\n",
      "              \"endTimeMs\": 11360,\n",
      "              \"text\": \"balance.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 11680,\n",
      "          \"endTimeMs\": 12560,\n",
      "          \"text\": \"No problem.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 11680,\n",
      "              \"endTimeMs\": 11920,\n",
      "              \"text\": \"No\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 11920,\n",
      "              \"endTimeMs\": 12560,\n",
      "              \"text\": \"problem.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 12880,\n",
      "          \"endTimeMs\": 13920,\n",
      "          \"text\": \"I am happy to help.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 12880,\n",
      "              \"endTimeMs\": 13000,\n",
      "              \"text\": \"I\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 13000,\n",
      "              \"endTimeMs\": 13120,\n",
      "              \"text\": \"am\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 13120,\n",
      "              \"endTimeMs\": 13480,\n",
      "              \"text\": \"happy\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 13480,\n",
      "              \"endTimeMs\": 13560,\n",
      "              \"text\": \"to\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 13560,\n",
      "              \"endTimeMs\": 13920,\n",
      "              \"text\": \"help.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 14240,\n",
      "          \"endTimeMs\": 16720,\n",
      "          \"text\": \"I need your date of birth to confirm your identity.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 14240,\n",
      "              \"endTimeMs\": 14400,\n",
      "              \"text\": \"I\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 14400,\n",
      "              \"endTimeMs\": 14600,\n",
      "              \"text\": \"need\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 14600,\n",
      "              \"endTimeMs\": 14720,\n",
      "              \"text\": \"your\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 14720,\n",
      "              \"endTimeMs\": 14920,\n",
      "              \"text\": \"date\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 14920,\n",
      "              \"endTimeMs\": 15040,\n",
      "              \"text\": \"of\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 15040,\n",
      "              \"endTimeMs\": 15440,\n",
      "              \"text\": \"birth\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 15440,\n",
      "              \"endTimeMs\": 15560,\n",
      "              \"text\": \"to\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 15560,\n",
      "              \"endTimeMs\": 16000,\n",
      "              \"text\": \"confirm\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 16000,\n",
      "              \"endTimeMs\": 16160,\n",
      "              \"text\": \"your\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 16160,\n",
      "              \"endTimeMs\": 16720,\n",
      "              \"text\": \"identity.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Customer\",\n",
      "          \"startTimeMs\": 17120,\n",
      "          \"endTimeMs\": 19600,\n",
      "          \"text\": \"It is April 19th, 1988.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 17120,\n",
      "              \"endTimeMs\": 17280,\n",
      "              \"text\": \"It\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 17280,\n",
      "              \"endTimeMs\": 17440,\n",
      "              \"text\": \"is\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 17440,\n",
      "              \"endTimeMs\": 17760,\n",
      "              \"text\": \"April\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 17760,\n",
      "              \"endTimeMs\": 18480,\n",
      "              \"text\": \"19th,\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 18480,\n",
      "              \"endTimeMs\": 19600,\n",
      "              \"text\": \"1988.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 20000,\n",
      "          \"endTimeMs\": 20480,\n",
      "          \"text\": \"Great.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 20000,\n",
      "              \"endTimeMs\": 20480,\n",
      "              \"text\": \"Great.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 20800,\n",
      "          \"endTimeMs\": 24160,\n",
      "          \"text\": \"Your current point balance is 599 points.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 20800,\n",
      "              \"endTimeMs\": 21040,\n",
      "              \"text\": \"Your\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 21040,\n",
      "              \"endTimeMs\": 21360,\n",
      "              \"text\": \"current\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 21360,\n",
      "              \"endTimeMs\": 21600,\n",
      "              \"text\": \"point\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 21600,\n",
      "              \"endTimeMs\": 22160,\n",
      "              \"text\": \"balance\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 22160,\n",
      "              \"endTimeMs\": 22320,\n",
      "              \"text\": \"is\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 22320,\n",
      "              \"endTimeMs\": 23600,\n",
      "              \"text\": \"599\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 23600,\n",
      "              \"endTimeMs\": 24160,\n",
      "              \"text\": \"points.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 24560,\n",
      "          \"endTimeMs\": 26160,\n",
      "          \"text\": \"Do you need any more information?\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 24560,\n",
      "              \"endTimeMs\": 24680,\n",
      "              \"text\": \"Do\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 24680,\n",
      "              \"endTimeMs\": 24800,\n",
      "              \"text\": \"you\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 24800,\n",
      "              \"endTimeMs\": 25040,\n",
      "              \"text\": \"need\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 25040,\n",
      "              \"endTimeMs\": 25200,\n",
      "              \"text\": \"any\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 25200,\n",
      "              \"endTimeMs\": 25440,\n",
      "              \"text\": \"more\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 25440,\n",
      "              \"endTimeMs\": 26160,\n",
      "              \"text\": \"information?\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Customer\",\n",
      "          \"startTimeMs\": 26480,\n",
      "          \"endTimeMs\": 27200,\n",
      "          \"text\": \"No, thank you.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 26480,\n",
      "              \"endTimeMs\": 26640,\n",
      "              \"text\": \"No,\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 26640,\n",
      "              \"endTimeMs\": 26960,\n",
      "              \"text\": \"thank\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 26960,\n",
      "              \"endTimeMs\": 27200,\n",
      "              \"text\": \"you.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Customer\",\n",
      "          \"startTimeMs\": 27600,\n",
      "          \"endTimeMs\": 28320,\n",
      "          \"text\": \"That was all.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 27600,\n",
      "              \"endTimeMs\": 27800,\n",
      "              \"text\": \"That\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 27800,\n",
      "              \"endTimeMs\": 28000,\n",
      "              \"text\": \"was\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 28000,\n",
      "              \"endTimeMs\": 28320,\n",
      "              \"text\": \"all.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Customer\",\n",
      "          \"startTimeMs\": 28720,\n",
      "          \"endTimeMs\": 29360,\n",
      "          \"text\": \"Goodbye.\",\n",
      "          \"confidence\": 0.926,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 28720,\n",
      "              \"endTimeMs\": 29360,\n",
      "              \"text\": \"Goodbye.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"Agent\",\n",
      "          \"startTimeMs\": 29680,\n",
      "          \"endTimeMs\": 31920,\n",
      "          \"text\": \"You're welcome, goodbye a Cantoso.\",\n",
      "          \"confidence\": 0.413,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"startTimeMs\": 29680,\n",
      "              \"endTimeMs\": 29840,\n",
      "              \"text\": \"You're\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 29840,\n",
      "              \"endTimeMs\": 30400,\n",
      "              \"text\": \"welcome,\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 30640,\n",
      "              \"endTimeMs\": 31080,\n",
      "              \"text\": \"goodbye\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 31080,\n",
      "              \"endTimeMs\": 31120,\n",
      "              \"text\": \"a\"\n",
      "            },\n",
      "            {\n",
      "              \"startTimeMs\": 31120,\n",
      "              \"endTimeMs\": 31920,\n",
      "              \"text\": \"Cantoso.\"\n",
      "            }\n",
      "          ],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Analyzer ID: video-analyzer6c99d63a-c371-48b3-add8-f45b5478339e\n",
      "{\n",
      "  \"analyzerId\": \"video-analyzer6c99d63a-c371-48b3-add8-f45b5478339e\",\n",
      "  \"apiVersion\": \"2024-12-01-preview\",\n",
      "  \"createdAt\": \"2026-01-16T19:13:42Z\",\n",
      "  \"warnings\": [],\n",
      "  \"contents\": [\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:00.000 => 00:01.467\\n## Transcript\\n```\\nWEBVTT\\n\\n00:01.360 --> 00:06.640\\n<v Speaker>When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\\n```\\n## Key Frames\\n- 00:00.733 ![](keyFrame.733.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"A scenic aerial view of an island surrounded by the sea, showcasing the Flight Simulator and Microsoft Azure AI collaboration.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 0,\n",
      "      \"endTimeMs\": 1467,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        733\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 1360,\n",
      "          \"endTimeMs\": 6640,\n",
      "          \"text\": \"When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:01.467 => 00:03.233\\n## Transcript\\n```\\nWEBVTT\\n\\n00:01.360 --> 00:06.640\\n<v Speaker>When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\\n```\\n## Key Frames\\n- 00:02.067 ![](keyFrame.2067.jpg)\\n- 00:02.667 ![](keyFrame.2667.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"An indoor setting with modern design elements visible on the walls.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 1467,\n",
      "      \"endTimeMs\": 3233,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        2067,\n",
      "        2667\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 1360,\n",
      "          \"endTimeMs\": 6640,\n",
      "          \"text\": \"When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:03.233 => 00:07.367\\n## Transcript\\n```\\nWEBVTT\\n\\n00:01.360 --> 00:06.640\\n<v Speaker>When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n```\\n## Key Frames\\n- 00:04.067 ![](keyFrame.4067.jpg)\\n- 00:04.900 ![](keyFrame.4900.jpg)\\n- 00:05.733 ![](keyFrame.5733.jpg)\\n- 00:06.567 ![](keyFrame.6567.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"A visual representation of audio waveforms, suggesting a focus on sound or voice technology.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 3233,\n",
      "      \"endTimeMs\": 7367,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        4067,\n",
      "        4900,\n",
      "        5733,\n",
      "        6567\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 1360,\n",
      "          \"endTimeMs\": 6640,\n",
      "          \"text\": \"When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 7120,\n",
      "          \"endTimeMs\": 13320,\n",
      "          \"text\": \"To achieve that, we build a universal TTS model based on 3,000 hours of data.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:07.367 => 00:08.200\\n## Transcript\\n```\\nWEBVTT\\n\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n```\\n## Key Frames\\n- 00:07.800 ![](keyFrame.7800.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"Another indoor setting, featuring sleek, modern design.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 7367,\n",
      "      \"endTimeMs\": 8200,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        7800\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 7120,\n",
      "          \"endTimeMs\": 13320,\n",
      "          \"text\": \"To achieve that, we build a universal TTS model based on 3,000 hours of data.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:08.200 => 00:11.367\\n## Transcript\\n```\\nWEBVTT\\n\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n```\\n## Key Frames\\n- 00:09.000 ![](keyFrame.9000.jpg)\\n- 00:09.800 ![](keyFrame.9800.jpg)\\n- 00:10.600 ![](keyFrame.10600.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"An expansive view of a rural landscape with fields and structures, possibly a data center or tech facility.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 8200,\n",
      "      \"endTimeMs\": 11367,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        9000,\n",
      "        9800,\n",
      "        10600\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 7120,\n",
      "          \"endTimeMs\": 13320,\n",
      "          \"text\": \"To achieve that, we build a universal TTS model based on 3,000 hours of data.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:11.367 => 00:13.567\\n## Transcript\\n```\\nWEBVTT\\n\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:12.100 ![](keyFrame.12100.jpg)\\n- 00:12.833 ![](keyFrame.12833.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"A dimly lit hallway filled with servers, indicating a data center environment.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 11367,\n",
      "      \"endTimeMs\": 13567,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        12100,\n",
      "        12833\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 7120,\n",
      "          \"endTimeMs\": 13320,\n",
      "          \"text\": \"To achieve that, we build a universal TTS model based on 3,000 hours of data.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 13440,\n",
      "          \"endTimeMs\": 23680,\n",
      "          \"text\": \"We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:13.567 => 00:16.100\\n## Transcript\\n```\\nWEBVTT\\n\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:14.200 ![](keyFrame.14200.jpg)\\n- 00:14.833 ![](keyFrame.14833.jpg)\\n- 00:15.467 ![](keyFrame.15467.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"An indoor setting with contemporary design features on the walls.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 13567,\n",
      "      \"endTimeMs\": 16100,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        14200,\n",
      "        14833,\n",
      "        15467\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 13440,\n",
      "          \"endTimeMs\": 23680,\n",
      "          \"text\": \"We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:16.100 => 00:19.433\\n## Transcript\\n```\\nWEBVTT\\n\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:16.933 ![](keyFrame.16933.jpg)\\n- 00:17.767 ![](keyFrame.17767.jpg)\\n- 00:18.600 ![](keyFrame.18600.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"A vibrant aerial shot of a biplane flying over coastal landscapes, showcasing natural beauty.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 16100,\n",
      "      \"endTimeMs\": 19433,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        16933,\n",
      "        17767,\n",
      "        18600\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 13440,\n",
      "          \"endTimeMs\": 23680,\n",
      "          \"text\": \"We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:19.433 => 00:23.967\\n## Transcript\\n```\\nWEBVTT\\n\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:20.167 ![](keyFrame.20167.jpg)\\n- 00:20.900 ![](keyFrame.20900.jpg)\\n- 00:21.633 ![](keyFrame.21633.jpg)\\n- 00:22.367 ![](keyFrame.22367.jpg)\\n- 00:23.100 ![](keyFrame.23100.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"A plane flying past a historical castle with mountains and clouds in the background.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 19433,\n",
      "      \"endTimeMs\": 23967,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        20167,\n",
      "        20900,\n",
      "        21633,\n",
      "        22367,\n",
      "        23100\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 13440,\n",
      "          \"endTimeMs\": 23680,\n",
      "          \"text\": \"We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:23.967 => 00:30.033\\n## Transcript\\n```\\nWEBVTT\\n\\n00:24.040 --> 00:29.120\\n<v Speaker>What we liked about cognitive services offerings were that they had a much higher fidelity.\\n00:29.600 --> 00:32.880\\n<v Speaker>And they sounded a lot more like an actual human voice.\\n```\\n## Key Frames\\n- 00:24.833 ![](keyFrame.24833.jpg)\\n- 00:25.700 ![](keyFrame.25700.jpg)\\n- 00:26.567 ![](keyFrame.26567.jpg)\\n- 00:27.433 ![](keyFrame.27433.jpg)\\n- 00:28.300 ![](keyFrame.28300.jpg)\\n- 00:29.167 ![](keyFrame.29167.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"An indoor office setting with modern architecture and design.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 23967,\n",
      "      \"endTimeMs\": 30033,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        24833,\n",
      "        25700,\n",
      "        26567,\n",
      "        27433,\n",
      "        28300,\n",
      "        29167\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 24040,\n",
      "          \"endTimeMs\": 29120,\n",
      "          \"text\": \"What we liked about cognitive services offerings were that they had a much higher fidelity.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        },\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 29600,\n",
      "          \"endTimeMs\": 32880,\n",
      "          \"text\": \"And they sounded a lot more like an actual human voice.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:30.033 => 00:33.200\\n## Transcript\\n```\\nWEBVTT\\n\\n00:29.600 --> 00:32.880\\n<v Speaker>And they sounded a lot more like an actual human voice.\\n```\\n## Key Frames\\n- 00:30.833 ![](keyFrame.30833.jpg)\\n- 00:31.633 ![](keyFrame.31633.jpg)\\n- 00:32.433 ![](keyFrame.32433.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"A closer view of the indoor office environment, highlighting the design and lighting.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 30033,\n",
      "      \"endTimeMs\": 33200,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        30833,\n",
      "        31633,\n",
      "        32433\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 29600,\n",
      "          \"endTimeMs\": 32880,\n",
      "          \"text\": \"And they sounded a lot more like an actual human voice.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:33.200 => 00:35.267\\n## Transcript\\n```\\nWEBVTT\\n\\n00:33.680 --> 00:37.200\\n<v Speaker>Orlando ground 9555 requesting the end of pushback.\\n```\\n## Key Frames\\n- 00:33.900 ![](keyFrame.33900.jpg)\\n- 00:34.600 ![](keyFrame.34600.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"An overhead view of an airplane on the tarmac, with its nose directed forward.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 33200,\n",
      "      \"endTimeMs\": 35267,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        33900,\n",
      "        34600\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 33680,\n",
      "          \"endTimeMs\": 37200,\n",
      "          \"text\": \"Orlando ground 9555 requesting the end of pushback.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:35.267 => 00:37.700\\n## Transcript\\n```\\nWEBVTT\\n\\n00:33.680 --> 00:37.200\\n<v Speaker>Orlando ground 9555 requesting the end of pushback.\\n```\\n## Key Frames\\n- 00:36.067 ![](keyFrame.36067.jpg)\\n- 00:36.867 ![](keyFrame.36867.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"A ground crew member signaling to an Airbus aircraft, preparing for movement.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 35267,\n",
      "      \"endTimeMs\": 37700,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        36067,\n",
      "        36867\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 33680,\n",
      "          \"endTimeMs\": 37200,\n",
      "          \"text\": \"Orlando ground 9555 requesting the end of pushback.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:37.700 => 00:39.200\\n## Transcript\\n```\\nWEBVTT\\n\\n00:38.680 --> 00:41.280\\n<v Speaker>9555 request to end pushback received.\\n```\\n## Key Frames\\n- 00:38.200 ![](keyFrame.38200.jpg)\\n- 00:38.700 ![](keyFrame.38700.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"Ground crew members positioned on an airport tarmac, with airplanes and terminal buildings in the background.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 37700,\n",
      "      \"endTimeMs\": 39200,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        38200,\n",
      "        38700\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 38680,\n",
      "          \"endTimeMs\": 41280,\n",
      "          \"text\": \"9555 request to end pushback received.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:39.200 => 00:42.033\\n## Transcript\\n```\\nWEBVTT\\n\\n00:38.680 --> 00:41.280\\n<v Speaker>9555 request to end pushback received.\\n```\\n## Key Frames\\n- 00:39.900 ![](keyFrame.39900.jpg)\\n- 00:40.600 ![](keyFrame.40600.jpg)\\n- 00:41.300 ![](keyFrame.41300.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"An Airbus aircraft is shown at an airport gate. The lighting suggests early morning or late afternoon, with a warm glow on the plane's fuselage. This coincides with the audio indicating a request to end pushback, suggesting the aircraft is preparing for departure.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 39200,\n",
      "      \"endTimeMs\": 42033,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        39900,\n",
      "        40600,\n",
      "        41300\n",
      "      ],\n",
      "      \"transcriptPhrases\": [\n",
      "        {\n",
      "          \"speaker\": \"speaker\",\n",
      "          \"startTimeMs\": 38680,\n",
      "          \"endTimeMs\": 41280,\n",
      "          \"text\": \"9555 request to end pushback received.\",\n",
      "          \"confidence\": 1,\n",
      "          \"words\": [],\n",
      "          \"locale\": \"en-US\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"markdown\": \"# Shot 00:42.033 => 00:43.866\\n## Transcript\\n```\\nWEBVTT\\n\\n```\\n## Key Frames\\n- 00:42.633 ![](keyFrame.42633.jpg)\\n- 00:43.233 ![](keyFrame.43233.jpg)\",\n",
      "      \"fields\": {\n",
      "        \"segmentDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"valueString\": \"The screen transitions to a black background displaying the Microsoft logo, indicating a shift in focus or sponsorship.\"\n",
      "        }\n",
      "      },\n",
      "      \"kind\": \"audioVisual\",\n",
      "      \"startTimeMs\": 42033,\n",
      "      \"endTimeMs\": 43866,\n",
      "      \"width\": 1080,\n",
      "      \"height\": 608,\n",
      "      \"KeyFrameTimesMs\": [\n",
      "        42633,\n",
      "        43233\n",
      "      ],\n",
      "      \"transcriptPhrases\": []\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Iterate through each analyzer created and analyze content for each modality\n",
    "\n",
    "analyzer_results =[]\n",
    "extracted_markdown = []\n",
    "analyzer_content = []\n",
    "for analyzer in analyzer_configs:\n",
    "    analyzer_id = analyzer[\"id\"]\n",
    "    template_path = analyzer[\"template_path\"]\n",
    "    file_location = analyzer[\"location\"]\n",
    "    try:\n",
    "           # Analyze content\n",
    "            response = content_understanding_client.begin_analyze(analyzer_id, file_location)\n",
    "            result = content_understanding_client.poll_result(response)\n",
    "            analyzer_results.append({\"id\":analyzer_id, \"result\": result[\"result\"]})\n",
    "            analyzer_content.append({\"id\": analyzer_id, \"content\": result[\"result\"][\"contents\"]})\n",
    "                       \n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error in creating analyzer. Please double-check your analysis settings.\\nIf there is a conflict, you can delete the analyzer and then recreate it, or move to the next cell and use the existing analyzer.\")\n",
    "\n",
    "print(\"Analyzer Results:\")\n",
    "for analyzer_result in analyzer_results:\n",
    "    print(f\"Analyzer ID: {analyzer_result['id']}\")\n",
    "    print(json.dumps(analyzer_result[\"result\"], indent=2))            \n",
    "\n",
    "# Delete the analyzer if it is no longer needed\n",
    "#content_understanding_client.delete_analyzer(ANALYZER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize multimodal data\n",
    "This is a simple starting point. Feel free to give your own chunking strategies a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess JSON output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19 documents.\n",
      "doc content This is a json string representing a document with text and metadata for the file located in ../data/credit_card_application_JessicaSmith.pdf {'markdown': \"# Credit Card Application For Woodgrove Bank\\n\\n\\n## Personal Identification Details\\n\\nFirst Name: Jessica\\n\\nLast Name: Smith\\n\\nDate of Birth: 1990-05-15\\n\\nGender: Female\\n\\n\\n## Contact & Address Information\\n\\nEmail: jessica.smith@example.com\\n\\nPhone: (555) 123-4567\\n\\nAddress: 123 Main Street\\n\\nCity: Cityville\\n\\nState: CA\\n\\nZip Code: 90210\\n\\nYears Stayed at Current Address: 5\\n\\n\\n## Employment & Income Information\\n\\nEmployment Status: Full-Time\\n\\nYears in Job: 7\\n\\nEducation: Bachelor's Degree\\n\\nSource of Income: Salary\\n\\nMonthly Income: $6,500\\n\\nMonthly Expenses: $3,000\\n\\nMonthly Mortgage: $1,200\\n\\n\\n## Financial & Banking Information\\n\\nBank Name: Woodgrove Bank\\n\\nType of Account: Checking\\n\\nCredit Score: 750\\n\\nCard Preferences\\n\\nPreferred Card: Woodgrove Platinum Credit Card\\n\\nConsent & Agreements\\n\\n\\nI agree to terms and conditions\\n\", 'kind': 'document', 'startPageNumber': 1, 'endPageNumber': 1, 'unit': 'inch', 'pages': [{'pageNumber': 1, 'angle': 0.02742189, 'width': 8.5, 'height': 11}]}```\n",
      "doc content This is a json string representing an image verbalization and OCR extraction for the file located in ../data/SSN_JessicaSmith.png {'markdown': '![image](image)\\n', 'fields': {'Title': {'type': 'string', 'valueString': 'Social Security Card'}, 'ChartType': {'type': 'string', 'valueString': 'box'}, 'TopicKeywords': {'type': 'array', 'valueArray': [{'type': 'string', 'valueString': 'Identification'}, {'type': 'string', 'valueString': 'Personal Information'}, {'type': 'string', 'valueString': 'Social Security'}]}, 'DetailedDescription': {'type': 'string', 'valueString': \"The image is a representation of a Social Security card. It features the text 'SOCIAL SECURITY' at the top. Below that, there is a placeholder for a Social Security Number (SSN) formatted as '123-45-6789'. The text 'is valid for SOCIAL SECURITY ADMINISTRATION' is printed in red below the SSN. The name 'JESSICA SMITH' is prominently displayed in the center. At the bottom, there is a line labeled 'SIGNATUAURE' for a signature.\"}, 'Summary': {'type': 'string', 'valueString': \"This is a mock-up of a Social Security card, showing a sample SSN and the name 'Jessica Smith'. It includes standard elements like the SSN, name, and a signature line.\"}, 'MarkdownDataTable': {'type': 'string', 'valueString': ''}, 'AxisTitles': {'type': 'object', 'valueObject': {'xAxisTitle': {'type': 'string', 'valueString': ''}, 'yAxisTitle': {'type': 'string', 'valueString': ''}}}, 'FootnotesAndAnnotations': {'type': 'string', 'valueString': ''}}, 'kind': 'document', 'startPageNumber': 1, 'endPageNumber': 1, 'unit': 'pixel', 'pages': [{'pageNumber': 1}]}```\n",
      "doc content This is a json string representing an audio segment with transcription for the file located in ../data/callCenterRecording.mp3 {'markdown': \"```WEBVTT\\n\\n00:00.080 --> 00:00.640\\n<v Agent>Good day.\\n\\n00:00.880 --> 00:02.240\\n<v Agent>Welcome to Contoso.\\n\\n00:02.560 --> 00:03.760\\n<v Agent>My name is John Doe.\\n\\n00:03.920 --> 00:05.120\\n<v Agent>How can I help you today?\\n\\n00:05.440 --> 00:06.320\\n<v Customer>Yes, good day.\\n\\n00:06.640 --> 00:08.160\\n<v Customer>My name is Maria Smith.\\n\\n00:08.560 --> 00:11.360\\n<v Customer>I would like to inquire about my current point balance.\\n\\n00:11.680 --> 00:12.560\\n<v Agent>No problem.\\n\\n00:12.880 --> 00:13.920\\n<v Agent>I am happy to help.\\n\\n00:14.240 --> 00:16.720\\n<v Agent>I need your date of birth to confirm your identity.\\n\\n00:17.120 --> 00:19.600\\n<v Customer>It is April 19th, 1988.\\n\\n00:20.000 --> 00:20.480\\n<v Agent>Great.\\n\\n00:20.800 --> 00:24.160\\n<v Agent>Your current point balance is 599 points.\\n\\n00:24.560 --> 00:26.160\\n<v Agent>Do you need any more information?\\n\\n00:26.480 --> 00:27.200\\n<v Customer>No, thank you.\\n\\n00:27.600 --> 00:28.320\\n<v Customer>That was all.\\n\\n00:28.720 --> 00:29.360\\n<v Customer>Goodbye.\\n\\n00:29.680 --> 00:31.920\\n<v Agent>You're welcome, goodbye a Cantoso.```\", 'fields': {'Sentiment': {'type': 'string', 'valueString': 'Neutral'}, 'Summary': {'type': 'string', 'valueString': 'Maria Smith contacted Contoso to inquire about her current point balance. Agent John Doe assisted her by confirming her identity and informing her that she has 599 points. Maria thanked the agent and ended the call.'}, 'Categories': {'type': 'array', 'valueArray': [{'type': 'string', 'valueString': 'Retail'}]}, 'Companies': {'type': 'array', 'valueArray': [{'type': 'string', 'valueString': 'Contoso'}]}, 'People': {'type': 'array', 'valueArray': [{'type': 'object', 'valueObject': {'Name': {'type': 'string', 'valueString': 'John Doe'}, 'Role': {'type': 'string', 'valueString': 'Agent'}}}, {'type': 'object', 'valueObject': {'Name': {'type': 'string', 'valueString': 'Maria Smith'}, 'Role': {'type': 'string', 'valueString': 'Customer'}}}]}, 'Topics': {'type': 'array', 'valueArray': [{'type': 'string', 'valueString': 'Point balance inquiry'}, {'type': 'string', 'valueString': 'Customer service'}, {'type': 'string', 'valueString': 'Identity confirmation'}, {'type': 'string', 'valueString': 'Contoso services'}, {'type': 'string', 'valueString': 'Account information'}]}}, 'kind': 'audioVisual', 'startTimeMs': 0, 'endTimeMs': 32182, 'transcriptPhrases': [{'speaker': 'Agent', 'startTimeMs': 80, 'endTimeMs': 640, 'text': 'Good day.', 'confidence': 0.926, 'words': [{'startTimeMs': 80, 'endTimeMs': 280, 'text': 'Good'}, {'startTimeMs': 280, 'endTimeMs': 640, 'text': 'day.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 880, 'endTimeMs': 2240, 'text': 'Welcome to Contoso.', 'confidence': 0.926, 'words': [{'startTimeMs': 880, 'endTimeMs': 1360, 'text': 'Welcome'}, {'startTimeMs': 1360, 'endTimeMs': 1480, 'text': 'to'}, {'startTimeMs': 1480, 'endTimeMs': 2240, 'text': 'Contoso.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 2560, 'endTimeMs': 3760, 'text': 'My name is John Doe.', 'confidence': 0.926, 'words': [{'startTimeMs': 2560, 'endTimeMs': 2720, 'text': 'My'}, {'startTimeMs': 2720, 'endTimeMs': 2960, 'text': 'name'}, {'startTimeMs': 2960, 'endTimeMs': 3120, 'text': 'is'}, {'startTimeMs': 3120, 'endTimeMs': 3440, 'text': 'John'}, {'startTimeMs': 3440, 'endTimeMs': 3760, 'text': 'Doe.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 3920, 'endTimeMs': 5120, 'text': 'How can I help you today?', 'confidence': 0.926, 'words': [{'startTimeMs': 3920, 'endTimeMs': 4120, 'text': 'How'}, {'startTimeMs': 4120, 'endTimeMs': 4240, 'text': 'can'}, {'startTimeMs': 4240, 'endTimeMs': 4320, 'text': 'I'}, {'startTimeMs': 4320, 'endTimeMs': 4640, 'text': 'help'}, {'startTimeMs': 4640, 'endTimeMs': 4720, 'text': 'you'}, {'startTimeMs': 4720, 'endTimeMs': 5120, 'text': 'today?'}], 'locale': 'en-US'}, {'speaker': 'Customer', 'startTimeMs': 5440, 'endTimeMs': 6320, 'text': 'Yes, good day.', 'confidence': 0.926, 'words': [{'startTimeMs': 5440, 'endTimeMs': 5760, 'text': 'Yes,'}, {'startTimeMs': 5760, 'endTimeMs': 5960, 'text': 'good'}, {'startTimeMs': 5960, 'endTimeMs': 6320, 'text': 'day.'}], 'locale': 'en-US'}, {'speaker': 'Customer', 'startTimeMs': 6640, 'endTimeMs': 8160, 'text': 'My name is Maria Smith.', 'confidence': 0.926, 'words': [{'startTimeMs': 6640, 'endTimeMs': 6880, 'text': 'My'}, {'startTimeMs': 6880, 'endTimeMs': 7120, 'text': 'name'}, {'startTimeMs': 7120, 'endTimeMs': 7280, 'text': 'is'}, {'startTimeMs': 7280, 'endTimeMs': 7680, 'text': 'Maria'}, {'startTimeMs': 7680, 'endTimeMs': 8160, 'text': 'Smith.'}], 'locale': 'en-US'}, {'speaker': 'Customer', 'startTimeMs': 8560, 'endTimeMs': 11360, 'text': 'I would like to inquire about my current point balance.', 'confidence': 0.926, 'words': [{'startTimeMs': 8560, 'endTimeMs': 8640, 'text': 'I'}, {'startTimeMs': 8640, 'endTimeMs': 8800, 'text': 'would'}, {'startTimeMs': 8800, 'endTimeMs': 9040, 'text': 'like'}, {'startTimeMs': 9040, 'endTimeMs': 9200, 'text': 'to'}, {'startTimeMs': 9200, 'endTimeMs': 9720, 'text': 'inquire'}, {'startTimeMs': 9720, 'endTimeMs': 9920, 'text': 'about'}, {'startTimeMs': 9920, 'endTimeMs': 10080, 'text': 'my'}, {'startTimeMs': 10080, 'endTimeMs': 10440, 'text': 'current'}, {'startTimeMs': 10440, 'endTimeMs': 10720, 'text': 'point'}, {'startTimeMs': 10720, 'endTimeMs': 11360, 'text': 'balance.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 11680, 'endTimeMs': 12560, 'text': 'No problem.', 'confidence': 0.926, 'words': [{'startTimeMs': 11680, 'endTimeMs': 11920, 'text': 'No'}, {'startTimeMs': 11920, 'endTimeMs': 12560, 'text': 'problem.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 12880, 'endTimeMs': 13920, 'text': 'I am happy to help.', 'confidence': 0.926, 'words': [{'startTimeMs': 12880, 'endTimeMs': 13000, 'text': 'I'}, {'startTimeMs': 13000, 'endTimeMs': 13120, 'text': 'am'}, {'startTimeMs': 13120, 'endTimeMs': 13480, 'text': 'happy'}, {'startTimeMs': 13480, 'endTimeMs': 13560, 'text': 'to'}, {'startTimeMs': 13560, 'endTimeMs': 13920, 'text': 'help.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 14240, 'endTimeMs': 16720, 'text': 'I need your date of birth to confirm your identity.', 'confidence': 0.926, 'words': [{'startTimeMs': 14240, 'endTimeMs': 14400, 'text': 'I'}, {'startTimeMs': 14400, 'endTimeMs': 14600, 'text': 'need'}, {'startTimeMs': 14600, 'endTimeMs': 14720, 'text': 'your'}, {'startTimeMs': 14720, 'endTimeMs': 14920, 'text': 'date'}, {'startTimeMs': 14920, 'endTimeMs': 15040, 'text': 'of'}, {'startTimeMs': 15040, 'endTimeMs': 15440, 'text': 'birth'}, {'startTimeMs': 15440, 'endTimeMs': 15560, 'text': 'to'}, {'startTimeMs': 15560, 'endTimeMs': 16000, 'text': 'confirm'}, {'startTimeMs': 16000, 'endTimeMs': 16160, 'text': 'your'}, {'startTimeMs': 16160, 'endTimeMs': 16720, 'text': 'identity.'}], 'locale': 'en-US'}, {'speaker': 'Customer', 'startTimeMs': 17120, 'endTimeMs': 19600, 'text': 'It is April 19th, 1988.', 'confidence': 0.926, 'words': [{'startTimeMs': 17120, 'endTimeMs': 17280, 'text': 'It'}, {'startTimeMs': 17280, 'endTimeMs': 17440, 'text': 'is'}, {'startTimeMs': 17440, 'endTimeMs': 17760, 'text': 'April'}, {'startTimeMs': 17760, 'endTimeMs': 18480, 'text': '19th,'}, {'startTimeMs': 18480, 'endTimeMs': 19600, 'text': '1988.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 20000, 'endTimeMs': 20480, 'text': 'Great.', 'confidence': 0.926, 'words': [{'startTimeMs': 20000, 'endTimeMs': 20480, 'text': 'Great.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 20800, 'endTimeMs': 24160, 'text': 'Your current point balance is 599 points.', 'confidence': 0.926, 'words': [{'startTimeMs': 20800, 'endTimeMs': 21040, 'text': 'Your'}, {'startTimeMs': 21040, 'endTimeMs': 21360, 'text': 'current'}, {'startTimeMs': 21360, 'endTimeMs': 21600, 'text': 'point'}, {'startTimeMs': 21600, 'endTimeMs': 22160, 'text': 'balance'}, {'startTimeMs': 22160, 'endTimeMs': 22320, 'text': 'is'}, {'startTimeMs': 22320, 'endTimeMs': 23600, 'text': '599'}, {'startTimeMs': 23600, 'endTimeMs': 24160, 'text': 'points.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 24560, 'endTimeMs': 26160, 'text': 'Do you need any more information?', 'confidence': 0.926, 'words': [{'startTimeMs': 24560, 'endTimeMs': 24680, 'text': 'Do'}, {'startTimeMs': 24680, 'endTimeMs': 24800, 'text': 'you'}, {'startTimeMs': 24800, 'endTimeMs': 25040, 'text': 'need'}, {'startTimeMs': 25040, 'endTimeMs': 25200, 'text': 'any'}, {'startTimeMs': 25200, 'endTimeMs': 25440, 'text': 'more'}, {'startTimeMs': 25440, 'endTimeMs': 26160, 'text': 'information?'}], 'locale': 'en-US'}, {'speaker': 'Customer', 'startTimeMs': 26480, 'endTimeMs': 27200, 'text': 'No, thank you.', 'confidence': 0.926, 'words': [{'startTimeMs': 26480, 'endTimeMs': 26640, 'text': 'No,'}, {'startTimeMs': 26640, 'endTimeMs': 26960, 'text': 'thank'}, {'startTimeMs': 26960, 'endTimeMs': 27200, 'text': 'you.'}], 'locale': 'en-US'}, {'speaker': 'Customer', 'startTimeMs': 27600, 'endTimeMs': 28320, 'text': 'That was all.', 'confidence': 0.926, 'words': [{'startTimeMs': 27600, 'endTimeMs': 27800, 'text': 'That'}, {'startTimeMs': 27800, 'endTimeMs': 28000, 'text': 'was'}, {'startTimeMs': 28000, 'endTimeMs': 28320, 'text': 'all.'}], 'locale': 'en-US'}, {'speaker': 'Customer', 'startTimeMs': 28720, 'endTimeMs': 29360, 'text': 'Goodbye.', 'confidence': 0.926, 'words': [{'startTimeMs': 28720, 'endTimeMs': 29360, 'text': 'Goodbye.'}], 'locale': 'en-US'}, {'speaker': 'Agent', 'startTimeMs': 29680, 'endTimeMs': 31920, 'text': \"You're welcome, goodbye a Cantoso.\", 'confidence': 0.413, 'words': [{'startTimeMs': 29680, 'endTimeMs': 29840, 'text': \"You're\"}, {'startTimeMs': 29840, 'endTimeMs': 30400, 'text': 'welcome,'}, {'startTimeMs': 30640, 'endTimeMs': 31080, 'text': 'goodbye'}, {'startTimeMs': 31080, 'endTimeMs': 31120, 'text': 'a'}, {'startTimeMs': 31120, 'endTimeMs': 31920, 'text': 'Cantoso.'}], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': \"# Shot 00:00.000 => 00:01.467\\n## Transcript\\n```\\nWEBVTT\\n\\n00:01.360 --> 00:06.640\\n<v Speaker>When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\\n```\\n## Key Frames\\n- 00:00.733 ![](keyFrame.733.jpg)\", 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'A scenic aerial view of an island surrounded by the sea, showcasing the Flight Simulator and Microsoft Azure AI collaboration.'}}, 'kind': 'audioVisual', 'startTimeMs': 0, 'endTimeMs': 1467, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [733], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 1360, 'endTimeMs': 6640, 'text': \"When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\", 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': \"# Shot 00:01.467 => 00:03.233\\n## Transcript\\n```\\nWEBVTT\\n\\n00:01.360 --> 00:06.640\\n<v Speaker>When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\\n```\\n## Key Frames\\n- 00:02.067 ![](keyFrame.2067.jpg)\\n- 00:02.667 ![](keyFrame.2667.jpg)\", 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'An indoor setting with modern design elements visible on the walls.'}}, 'kind': 'audioVisual', 'startTimeMs': 1467, 'endTimeMs': 3233, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [2067, 2667], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 1360, 'endTimeMs': 6640, 'text': \"When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\", 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': \"# Shot 00:03.233 => 00:07.367\\n## Transcript\\n```\\nWEBVTT\\n\\n00:01.360 --> 00:06.640\\n<v Speaker>When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n```\\n## Key Frames\\n- 00:04.067 ![](keyFrame.4067.jpg)\\n- 00:04.900 ![](keyFrame.4900.jpg)\\n- 00:05.733 ![](keyFrame.5733.jpg)\\n- 00:06.567 ![](keyFrame.6567.jpg)\", 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'A visual representation of audio waveforms, suggesting a focus on sound or voice technology.'}}, 'kind': 'audioVisual', 'startTimeMs': 3233, 'endTimeMs': 7367, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [4067, 4900, 5733, 6567], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 1360, 'endTimeMs': 6640, 'text': \"When it comes to the neural TTS, in order to get a good voice, it's better to have good data.\", 'confidence': 1, 'words': [], 'locale': 'en-US'}, {'speaker': 'speaker', 'startTimeMs': 7120, 'endTimeMs': 13320, 'text': 'To achieve that, we build a universal TTS model based on 3,000 hours of data.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:07.367 => 00:08.200\\n## Transcript\\n```\\nWEBVTT\\n\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n```\\n## Key Frames\\n- 00:07.800 ![](keyFrame.7800.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'Another indoor setting, featuring sleek, modern design.'}}, 'kind': 'audioVisual', 'startTimeMs': 7367, 'endTimeMs': 8200, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [7800], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 7120, 'endTimeMs': 13320, 'text': 'To achieve that, we build a universal TTS model based on 3,000 hours of data.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:08.200 => 00:11.367\\n## Transcript\\n```\\nWEBVTT\\n\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n```\\n## Key Frames\\n- 00:09.000 ![](keyFrame.9000.jpg)\\n- 00:09.800 ![](keyFrame.9800.jpg)\\n- 00:10.600 ![](keyFrame.10600.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'An expansive view of a rural landscape with fields and structures, possibly a data center or tech facility.'}}, 'kind': 'audioVisual', 'startTimeMs': 8200, 'endTimeMs': 11367, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [9000, 9800, 10600], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 7120, 'endTimeMs': 13320, 'text': 'To achieve that, we build a universal TTS model based on 3,000 hours of data.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:11.367 => 00:13.567\\n## Transcript\\n```\\nWEBVTT\\n\\n00:07.120 --> 00:13.320\\n<v Speaker>To achieve that, we build a universal TTS model based on 3,000 hours of data.\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:12.100 ![](keyFrame.12100.jpg)\\n- 00:12.833 ![](keyFrame.12833.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'A dimly lit hallway filled with servers, indicating a data center environment.'}}, 'kind': 'audioVisual', 'startTimeMs': 11367, 'endTimeMs': 13567, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [12100, 12833], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 7120, 'endTimeMs': 13320, 'text': 'To achieve that, we build a universal TTS model based on 3,000 hours of data.', 'confidence': 1, 'words': [], 'locale': 'en-US'}, {'speaker': 'speaker', 'startTimeMs': 13440, 'endTimeMs': 23680, 'text': 'We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:13.567 => 00:16.100\\n## Transcript\\n```\\nWEBVTT\\n\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:14.200 ![](keyFrame.14200.jpg)\\n- 00:14.833 ![](keyFrame.14833.jpg)\\n- 00:15.467 ![](keyFrame.15467.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'An indoor setting with contemporary design features on the walls.'}}, 'kind': 'audioVisual', 'startTimeMs': 13567, 'endTimeMs': 16100, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [14200, 14833, 15467], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 13440, 'endTimeMs': 23680, 'text': 'We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:16.100 => 00:19.433\\n## Transcript\\n```\\nWEBVTT\\n\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:16.933 ![](keyFrame.16933.jpg)\\n- 00:17.767 ![](keyFrame.17767.jpg)\\n- 00:18.600 ![](keyFrame.18600.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'A vibrant aerial shot of a biplane flying over coastal landscapes, showcasing natural beauty.'}}, 'kind': 'audioVisual', 'startTimeMs': 16100, 'endTimeMs': 19433, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [16933, 17767, 18600], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 13440, 'endTimeMs': 23680, 'text': 'We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:19.433 => 00:23.967\\n## Transcript\\n```\\nWEBVTT\\n\\n00:13.440 --> 00:23.680\\n<v Speaker>We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.\\n```\\n## Key Frames\\n- 00:20.167 ![](keyFrame.20167.jpg)\\n- 00:20.900 ![](keyFrame.20900.jpg)\\n- 00:21.633 ![](keyFrame.21633.jpg)\\n- 00:22.367 ![](keyFrame.22367.jpg)\\n- 00:23.100 ![](keyFrame.23100.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'A plane flying past a historical castle with mountains and clouds in the background.'}}, 'kind': 'audioVisual', 'startTimeMs': 19433, 'endTimeMs': 23967, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [20167, 20900, 21633, 22367, 23100], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 13440, 'endTimeMs': 23680, 'text': 'We actually accumulated tons of the data so that this universal model is able to capture the nuance of the audio and generate a more natural voice for the algorithm.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:23.967 => 00:30.033\\n## Transcript\\n```\\nWEBVTT\\n\\n00:24.040 --> 00:29.120\\n<v Speaker>What we liked about cognitive services offerings were that they had a much higher fidelity.\\n00:29.600 --> 00:32.880\\n<v Speaker>And they sounded a lot more like an actual human voice.\\n```\\n## Key Frames\\n- 00:24.833 ![](keyFrame.24833.jpg)\\n- 00:25.700 ![](keyFrame.25700.jpg)\\n- 00:26.567 ![](keyFrame.26567.jpg)\\n- 00:27.433 ![](keyFrame.27433.jpg)\\n- 00:28.300 ![](keyFrame.28300.jpg)\\n- 00:29.167 ![](keyFrame.29167.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'An indoor office setting with modern architecture and design.'}}, 'kind': 'audioVisual', 'startTimeMs': 23967, 'endTimeMs': 30033, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [24833, 25700, 26567, 27433, 28300, 29167], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 24040, 'endTimeMs': 29120, 'text': 'What we liked about cognitive services offerings were that they had a much higher fidelity.', 'confidence': 1, 'words': [], 'locale': 'en-US'}, {'speaker': 'speaker', 'startTimeMs': 29600, 'endTimeMs': 32880, 'text': 'And they sounded a lot more like an actual human voice.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:30.033 => 00:33.200\\n## Transcript\\n```\\nWEBVTT\\n\\n00:29.600 --> 00:32.880\\n<v Speaker>And they sounded a lot more like an actual human voice.\\n```\\n## Key Frames\\n- 00:30.833 ![](keyFrame.30833.jpg)\\n- 00:31.633 ![](keyFrame.31633.jpg)\\n- 00:32.433 ![](keyFrame.32433.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'A closer view of the indoor office environment, highlighting the design and lighting.'}}, 'kind': 'audioVisual', 'startTimeMs': 30033, 'endTimeMs': 33200, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [30833, 31633, 32433], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 29600, 'endTimeMs': 32880, 'text': 'And they sounded a lot more like an actual human voice.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:33.200 => 00:35.267\\n## Transcript\\n```\\nWEBVTT\\n\\n00:33.680 --> 00:37.200\\n<v Speaker>Orlando ground 9555 requesting the end of pushback.\\n```\\n## Key Frames\\n- 00:33.900 ![](keyFrame.33900.jpg)\\n- 00:34.600 ![](keyFrame.34600.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'An overhead view of an airplane on the tarmac, with its nose directed forward.'}}, 'kind': 'audioVisual', 'startTimeMs': 33200, 'endTimeMs': 35267, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [33900, 34600], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 33680, 'endTimeMs': 37200, 'text': 'Orlando ground 9555 requesting the end of pushback.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:35.267 => 00:37.700\\n## Transcript\\n```\\nWEBVTT\\n\\n00:33.680 --> 00:37.200\\n<v Speaker>Orlando ground 9555 requesting the end of pushback.\\n```\\n## Key Frames\\n- 00:36.067 ![](keyFrame.36067.jpg)\\n- 00:36.867 ![](keyFrame.36867.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'A ground crew member signaling to an Airbus aircraft, preparing for movement.'}}, 'kind': 'audioVisual', 'startTimeMs': 35267, 'endTimeMs': 37700, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [36067, 36867], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 33680, 'endTimeMs': 37200, 'text': 'Orlando ground 9555 requesting the end of pushback.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:37.700 => 00:39.200\\n## Transcript\\n```\\nWEBVTT\\n\\n00:38.680 --> 00:41.280\\n<v Speaker>9555 request to end pushback received.\\n```\\n## Key Frames\\n- 00:38.200 ![](keyFrame.38200.jpg)\\n- 00:38.700 ![](keyFrame.38700.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'Ground crew members positioned on an airport tarmac, with airplanes and terminal buildings in the background.'}}, 'kind': 'audioVisual', 'startTimeMs': 37700, 'endTimeMs': 39200, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [38200, 38700], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 38680, 'endTimeMs': 41280, 'text': '9555 request to end pushback received.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:39.200 => 00:42.033\\n## Transcript\\n```\\nWEBVTT\\n\\n00:38.680 --> 00:41.280\\n<v Speaker>9555 request to end pushback received.\\n```\\n## Key Frames\\n- 00:39.900 ![](keyFrame.39900.jpg)\\n- 00:40.600 ![](keyFrame.40600.jpg)\\n- 00:41.300 ![](keyFrame.41300.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': \"An Airbus aircraft is shown at an airport gate. The lighting suggests early morning or late afternoon, with a warm glow on the plane's fuselage. This coincides with the audio indicating a request to end pushback, suggesting the aircraft is preparing for departure.\"}}, 'kind': 'audioVisual', 'startTimeMs': 39200, 'endTimeMs': 42033, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [39900, 40600, 41300], 'transcriptPhrases': [{'speaker': 'speaker', 'startTimeMs': 38680, 'endTimeMs': 41280, 'text': '9555 request to end pushback received.', 'confidence': 1, 'words': [], 'locale': 'en-US'}]}```\n",
      "doc content The following is a json string representing a video segment with scene description and transcript for the file located in ../data/FlightSimulator.mp4 {'markdown': '# Shot 00:42.033 => 00:43.866\\n## Transcript\\n```\\nWEBVTT\\n\\n```\\n## Key Frames\\n- 00:42.633 ![](keyFrame.42633.jpg)\\n- 00:43.233 ![](keyFrame.43233.jpg)', 'fields': {'segmentDescription': {'type': 'string', 'valueString': 'The screen transitions to a black background displaying the Microsoft logo, indicating a shift in focus or sponsorship.'}}, 'kind': 'audioVisual', 'startTimeMs': 42033, 'endTimeMs': 43866, 'width': 1080, 'height': 608, 'KeyFrameTimesMs': [42633, 43233], 'transcriptPhrases': []}```\n"
     ]
    }
   ],
   "source": [
    "def convert_values_to_strings(json_obj):\n",
    "    return [str(value) for value in json_obj]\n",
    "\n",
    "#process all content and convert to string      \n",
    "def process_allJSON_content(all_content):\n",
    "\n",
    "    # Initialize empty list to store string of all content\n",
    "    output = []\n",
    "\n",
    "    document_splits = [\n",
    "        \"This is a json string representing a document with text and metadata for the file located in \"+str(analyzer_configs[0][\"location\"])+\" \"\n",
    "        + v \n",
    "        + \"```\"\n",
    "        for v in convert_values_to_strings(all_content[0][\"content\"])\n",
    "    ]\n",
    "    docs = [Document(page_content=v) for v in document_splits]\n",
    "    output += docs\n",
    "\n",
    "    #convert image json object to string and append file metadata to the string\n",
    "    image_splits = [\n",
    "       \"This is a json string representing an image verbalization and OCR extraction for the file located in \"+str(analyzer_configs[1][\"location\"])+\" \"\n",
    "       + v\n",
    "       + \"```\"\n",
    "       for v in convert_values_to_strings(all_content[1][\"content\"])\n",
    "    ]\n",
    "    image = [Document(page_content=v) for v in image_splits]\n",
    "    output+=image\n",
    "\n",
    "    #convert audio json object to string and append file metadata to the string\n",
    "    audio_splits = [\n",
    "        \"This is a json string representing an audio segment with transcription for the file located in \"+str(analyzer_configs[2][\"location\"])+\" \" \n",
    "       + v\n",
    "       + \"```\"\n",
    "       for v in convert_values_to_strings(all_content[2][\"content\"])\n",
    "    ]\n",
    "    audio = [Document(page_content=v) for v in audio_splits]\n",
    "    output += audio\n",
    "\n",
    "    #convert video json object to string and append file metadata to the string\n",
    "    video_splits = [\n",
    "        \"The following is a json string representing a video segment with scene description and transcript for the file located in \"+str(analyzer_configs[3][\"location\"])+\" \"\n",
    "        + v\n",
    "        + \"```\"\n",
    "        for v in convert_values_to_strings(all_content[3][\"content\"])\n",
    "    ]\n",
    "    video = [Document(page_content=v) for v in video_splits]\n",
    "    output+=video    \n",
    "    \n",
    "    return output\n",
    "\n",
    "all_splits = process_allJSON_content(analyzer_content)\n",
    "\n",
    "print(\"There are \" + str(len(all_splits)) + \" documents.\") \n",
    "# Print the content of all doc splits\n",
    "for doc in all_splits:\n",
    "    print(f\"doc content\", doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Optional* - Split document markdown into semantic chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of splits: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configure langchain text splitting settings\n",
    "EMBEDDING_CHUNK_SIZE = 512\n",
    "EMBEDDING_CHUNK_OVERLAP = 20\n",
    "\n",
    "# Split the document into chunks base on markdown headers.\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "docs_string = analyzer_content[0]['content'][0]['markdown'] #extract document analyzer markdown (first item in the list) is the document analyzer markdown output\n",
    "docs_splits = text_splitter.split_text(docs_string)\n",
    "\n",
    "print(\"Length of splits: \" + str(len(docs_splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed and index the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the splitted documents and insert into Azure Search vector store\n",
    "def embed_and_index_chunks(docs):\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_EMBEDDING_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        azure_search_key=None,\n",
    "        index_name=AZURE_SEARCH_INDEX_NAME,\n",
    "        embedding_function=aoai_embeddings.embed_query\n",
    "    )\n",
    "    vector_store.add_documents(documents=docs)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "# embed and index the docs:\n",
    "vector_store = embed_and_index_chunks(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve relevant chunks based on a question\n",
    "#### Execute a pure vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your query\n",
    "query = \"japan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute hybrid search. Vector and nonvector text fields are queried in parallel, results are merged, and top matches of the unified result set are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search using the search_type parameter\n",
    "docs = vector_store.hybrid_search(query=query, k=3)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "We can utilize OpenAI GPT completion models + Azure Search to conversationally search for and chat about the results. (If you are using GitHub Codespaces, there will be an input prompt near the top of the screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup rag chain\n",
    "prompt_str = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "def setup_rag_chain(vector_store):\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", k=3)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "    llm = AzureChatOpenAI(\n",
    "        openai_api_version=AZURE_OPENAI_CHAT_API_VERSION,\n",
    "        azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "        azure_ad_token_provider=token_provider,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "# Setup conversational search\n",
    "def conversational_search(rag_chain, query):\n",
    "    print(rag_chain.invoke(query))\n",
    "\n",
    "\n",
    "rag_chain = setup_rag_chain(vector_store)\n",
    "while True:\n",
    "    query = input(\"Enter your query: \")\n",
    "    if query==\"\":\n",
    "        break\n",
    "    conversational_search(rag_chain, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
